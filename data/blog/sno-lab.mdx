---
title: 'Transform your old laptop into a Single Node OpenShift lab'
date: '2024-07-04'
tags: ['openshift', 'SNO', 'Lab', 'Tech Tutorial']
draft: true
summary: 'A simple step by step guide on having your own Single Node OpenShift cluster, featuring some useful storage considerations.'
---

# TL;DR

Anyone using OpenShift regularly would want to have their own small cluster at some points.
There are multiple ways to achieve that, one popular approach is to run OpenShift Local,
which is effectively a minimalistic Single Node OpenShift running in a VM, on your laptop.
I ran OpenShift Local for a while, but found several limitations I wanted to overcome.
Another simple way would be to run your own managed OpenShift ROSA or ARO cluster in AWS / Azure,
probably fine is work funds that, but a bit too pricey for a personal lab setup.
The option I settled for at the moment is to recycle an old laptop and turn that into a Single Node OpenShift (SNO).
There are several articles / blogs that deal with this kind of subject.
To my knowledge, none of them manage to deal easily with the question of storage. This one does hopefuly.
So read it, especially the bit about disk partitioning.

At a high level:

- Get some hardware
- Configure some basic cluster settings
- Configure some networking
- Pick a few Operators to be deployed automatically
- Generate an ISO

# Find the hardware.

A spare laptop with a NIC (usb-c to ethernet is fine), 8vCPU, and 16GB of RAM is enough to get started, though 16vCPU / 32GB will be more comfortable.
You also need some disk. You probably want 512GB of Disk as a minimum, but you can make it work with say 200GB.
In most cases, a laptop would have just one disk. By default, the OpenShift Assisted installer will consume the whole disk,
and you have no storage left for your OpenShift cluster itself. There are a couple of ways to try and fix that, we will review them later.

<figure>
  {' '}
  <img src="/static/images/sno-lab/lenovo.webp" alt="Spare laptop" width="200" />
</figure>

In my case, I have an old Lenovo W540 from 2015, it has 8vCPU and 32GB with 512GB SSD disk.
That’s perfect for a lab SNO. A NIC is also required of course, usb-c to ethernet does fine if your laptop doesn’t have an ethernet port.
Make sure you take note of your laptop `MAC address` (or your usb-c to ethernet adaptor `MAC address`), you will need it at some point.
For that, I use the linux command `ifconfig`, there are otherway.

# Create an account on redhat.com

Head to https://console.redhat.com/openshift If you have an account, just login, otherwise, create a new one.

<figure>
  {' '}
  <img src="/static/images/sno-lab/register1.png" alt="Register a red hat account" width="800" />
</figure>

You will have to enter some info, I know it’s a bit annoying, but it’s worth it.

# Create the cluster via the Assisted Installer

Once done, you should be able to reach [The hybrid cloud console](https://console.redhat.com/openshift).
From there, you can click on `create cluster`. There are many ways to create / install a cluster,
we are going to use the `Datacenter` tab, with the `Assisted Installer`. Assisted Installer is so simple, even I can do it.

<figure>
  {' '}
  <img src="/static/images/sno-lab/create-cluster1.png" alt="Create a cluster" width="800" />
</figure>

<figure>
  {' '}
  <img
    src="/static/images/sno-lab/create-cluster2.png"
    alt="Create a cluster"
    width="800"
    height="460"
  />
</figure>

## Cluster details

In the first “cluster details” form,

- you give your cluster a name, for example `lab`.
- You give it a domain name. I happen to own `cszevaco.com`, and can manage DNS via cloudflare. This makes my life easier. Alternatively, you can use any domain
  as long as you can install / manage / configure some local DNS. I think editing your normal linux computer file `/etc/hosts` would work too, but
  that's not my recommendation.
  My cluster will be under lab.cszevaco.com, and I will manage a couple of DNS entries via cloudflare.
- Make sure to check `SNO` for Single Node OpenShift. Otherwise, you will need at least 3 nodes.
- Make sure to check `Include custom manifests` This will let you add custom kubernetes resource, in particular, MachineConfig resrouces.
  This is particularly relevant if you only have one disk, and want to configure MachineConfig to get the partitioning done for you:

  - one partition for the OpenShift node install and system (Red Hat CoreOS),
  - the other partition to be used by OpenShift for a lvms storage class. You need a storage class to provision Persistent Volume / Persistent Volume Claim.
    Without that, your kubernetes workload won’t have any persistence, and you will be seriously limited.

- For the network configuration, the simplest is to use DHCP, but I have to use `Static IP, bridges and bonds`
  You will want your SNO to always be allocated the same IP address (upon reboot), and you can typically do that via your router/modem by configuring it to allocate a given
  IP address (say 192.168.1.128) for a given mac address (the one of your laptop NIC). In my case, sadly, the router I am using doesn’t let me do that, and
  I didn’t want to have to configure my own DHCP. So instead, I am configuring my SNO with static IP.

<figure>
  {' '}
  <img
    src="/static/images/sno-lab/create-cluster3.png"
    alt="cluster details configuration"
    width="800"
    height="460"
  />
</figure>

## Static Network Configuration - Network Wide configuration

Since I picked `Static IP, bridges and bonds` earlier, I will have to configure some details. You won't if you stick with DHCP.

- For the `DNS`, I typically use `8.8.8.8`. That's because I like google to know what I am doing, and I hope they poke me on Linkedin.
  You can also use a few other public one, or most likely, the one of router, which for a home router is usually 192.168.1.1
- Speaking of which, for the `Machine Network`, just use the network of your router, which typically is `192.168.1.1/24`.
  If you are currently connected to your network, `ifconfig` should return some info that help you understand your network.
- For the `Default gateway`, again, on a home router, it is often `192.168.1.1`. The linux command `route -n` is useful otherwise.

<figure>
  {' '}
  <img
    src="/static/images/sno-lab/create-cluster4.png"
    alt="Cluster network details configuration"
    width="800"
    height="460"
  />
</figure>

## Static Network Configuration - Host Specific configuration

Here, for each node (just one node for SNO), we can provide the maping between the NIC mac address, and the desired node IP.
In this case, I am going to assign 192.168.1.128 to my SNO

<figure>
  {' '}
  <img
    src="/static/images/sno-lab/create-cluster5.png"
    alt="Cluster network details configuration"
    width="800"
    height="460"
  />
</figure>

## Operators

<figure>
  {' '}
  <img
    src="/static/images/sno-lab/create-cluster6-lvms.png"
    alt="Cluster network details configuration"
    width="800"
    height="460"
  />
</figure>

# Introduction

We developers have evolved our practices over the last decades, to use more and more advanced IDEs on our laptops.
For my generation emacs was a great option, still used today, but probably not by younger generations who will
find the likes of Eclipse, VSCode, or Intellij more appealing.
We also evolved in the number of languages, frameworks, libraries, and backend services we need to understand, use, and master.
In the past, being good in one language, say C, C++, or Java was plenty to get any job.
Nowadays, the list of technical "must have" and "good to have"
requirements in any job advert is insane. This has led to the rise of the full stack developer, the jack of all trades master of none.
This got even more complicated with the emergence of the microservices architecture pattern,
where microservices are sometimes written in different languages, often in different language versions,
using different libraries, also in different versions, relying on different backend services, also in...
-you guessed it- different versions. Maintaining a development environment
on one's laptop, to cater for this diversity has become a monumental waste of time that unnecessarily adds to the mental load
of developers, in-turn reducing creative bandwidth for higher-order executive problem solving. Do you like fixing dependencies
and resolving conflicts? No-one does.

I believe, we, the developers have been the victims of the so called [boiling frog syndrome](https://en.wikipedia.org/wiki/Boiling_frog): A frog dropped inside a pot full
of safe cold water, which temperature has been increased year after year, without the frog sensing the danger of the water
temperature raising to boiling level, until that poor amphibian gets cooked to death.

<figure>
  {' '}
  <img
    src="/static/images/devspaces/frog-spa3.webp"
    alt="Frog having a Spa in a cooking pot"
    width="800"
    height="460"
  />
</figure>
{/* ![frogspa](/static/images/devspaces/frog-spa2.webp) */}

It's time to get out of this cooking pot before it's too late, and fix that once and for all.

# Containers to the rescue?

Containerized technology enjoyed a massive growth over the last decade. By encapsulating all the requirements of a given application
(think OS, libraries, runtime environment, code), containers ensure safe isolation and portability of that application. Unlike Virtual Machine,
containers are a few orders of magnitude faster to start, lighter to store, easier to transport, and agile to work with. It is the
supporting technology that has enabled the rise of microservices. Containers are now so ubiquitous, they are the defacto
solution for new projects, or the solutions of choice for legacy projects in need of modernisation.

<figure>
  {' '}
  <img
    src="/static/images/devspaces/frog-container2.webp"
    alt="Frog saved by a shipping container"
    width="800"
    height="460"
  />
</figure>

{/* ![frogcontainer](/static/images/devspaces/frog-container.webp) */}

This begs the question: If containers are so ubiquitous, if containerized systems brings so many benefits, why don't we, the developers
use a containerized IDE in the first place?

# OpenShift solution

There are several solutions that tackle this problem by leveraging the agility of containers. OpenShift Dev Spaces is one of them. It uses
two upstream open source projects:

- [Devfile](devfile.io) is an open standard that let you codify your Developement Environment. Red Hat, IBM, AWS, JetBrains and Gitlab are contributing this CNCF project.
- [Eclipse che](https://eclipse.dev/che/) provides your IDE in Kubernetes, leveraging Devfiles.

Together this solution provides major benefits as explained below.

## Standardized IDE as code

The same way containers are codified via Dockerfiles, Dev Spaces are codified via devfile.yaml.
This file typically sits inside your project git repo, but can also
be hosted in a devfile registry provided by OpenShift Dev Spaces. This file is typically customized for each project language and requirements, and lets you, among other things:

- Define some components (think sidecar containers) providing you with the services (think Databases, Message Brokers, CLI tools etc...) required for development purposes.
- Define your library of useful commands: Those helper commands that developers constantly rely for their work (compile command lines, debugs, test, cleanup and load db etc...)

You can also tailor the base image used to deliver the workspace (in OpenShift, that's the Red Hat Universal Developer Image, the upstream project
can be found [here](https://github.com/devfile/developer-images))

<figure>
  {' '}
  <img
    src="/static/images/devspaces/frog-blueprint2.webp"
    alt="Frog saved by a shipping container"
    width="800"
    height="460"
  />
</figure>

With a codified IDE, you have a standardised development platform across all the devs of a given project. All developers can contribute to this devfile, adding,
and hence, sharing their best practice.

## One project, one IDE, instant onboarding

This is probably the most important benefit. Most (all?) developers struggle to maintain their IDE on their laptop, when juggling across projects,
languages, libraries all in different versions. The amount of time and frustration spent on framework conflicts, setting up a build toolchain for a new project,
and maintaining that, fixing dependencies, fighting version conflicts, adding that Database or that message broker to it in the right version for that project... That's enough.

For the Python language, this issue has been captured a while back by this [xkcd comic](https://xkcd.com/1987/)

<figure>
  {' '}
  <img
    src="/static/images/devspaces/frog-python.png"
    alt="Python dependency nightmare"
    width="800"
    height="800"
  />
</figure>

What's crazy? Nowadays, each git project has typically a lengthy, out-of-date README to help setup the environment. This README is the hint that
a developer environment should be project specific. It then makes perfect sense to containerise such a developer environment, for each project, right?

## Breaking silos

Forgive me for using a buzz word, but it's just true, our current approach leads to silos. One reason teams and projects are siloed
is the difficulty to get started on another teams project. Just to be in a position to make some small changes or
sort bug fixes or to learn from that other project you face a `cost of admission` to that developer environment which is motivationally prohibitive. Being able to start a configured and ready to use IDE for any project, at the click of a button (last buzzword today
I promiss) is an invitation to explore and collaborate on anyone's project. Break that silo, now!

<figure>
  {' '}
  <img
    src="/static/images/devspaces/frog-silos.webp"
    alt="Breaking silos"
    width="800"
    height="460"
  />
</figure>

## Security

It may sound obvious, but not having to checkout the git project on personal laptop just add another layer of security.
The code now lives only on the git repository, and on the Dev Spaces workspace on that OpenShift cluster.
So much easier and safer.

## Cost savings

There is a huge cost saving opportunity, it depends on your organizations situation. First of all, for OpenShift customers,
OpenShift Dev Spaces is included in your subscription. You can get started immediatly.

Efficiency is time, time is money,
teams that effectively adopt Dev Spaces (or other similar solutions, do your research) will save money:

- onboarding is much faster
- developers will jump more easily from project to project
- developers laptop can be lighter (in price, but also, in kg)
- developer environment maintenance is now centralized via the devfile. Only one team lead needs to maintain it for
  everyone, yet every team member can contribute and improve it! Hello colaborative Development Environment.
- Kubernetes will make CPU usage more elastic, providing more resources when developers need it (compile, build and test time), yet use little resources when iddle.

For none OpenShift users, well, Devfile and eclipse Che are open source, you could leverage them, build a solution around them, and maintain them as needed.

## Limitations

In all honestly, the only limitations I could find are:

- native apps, such as the postman app, can't be containerized to run on OpenShift. Only CLI tools, or web based applications can run as side care containers.
  That covers the majority of devtools in my opinion, as for that postman example, it
  has had a [web based offering](https://identity.getpostman.com/signup) for a while. Postman alternatives can be used as VSCode extensions too. Obviously, Postman
  may still run on a Developer's laptop.
- VSCode extensions that can be run are available on the [open vsx site](https://open-vsx.org/). It covers most of VSCode extensions, yet a few are missing. On a related
  note, it's possible to create a private registry (think disconnected environment) when needed. Dev Spaces can run disconnected.
- OpenShift Dev Spaces offers the choice of VSCode and Intellij, with the later in tech preview as of now.

## Next step

For OpenShift customers, you will need to install the Dev Spaces operator, and instanciate a Che cluster resource. That's enough to get started.
For none OpenShift customers, you can try Dev Spaces via the [Red Hat OpenShift Developer Sandbox](https://developers.redhat.com/developer-sandbox/ide)

# Conclusion

In this current decade, we are at the intersection of two things:

- developers are in urgent need of better working paradigm
- the technology has now matured to support this paradigm

It's time to change habits, take a leap frog, and embrace a new and modern way to deliver IDEs.
It's time to let go of the era of the beeffy laptop, and instead harvest the power
and convenience of kubernetes platforms such as OpenShift.

<figure>
  {' '}
  <img
    src="/static/images/devspaces/frog-revolution3.webp"
    alt="The Frog Revolution"
    width="800"
    height="460"
  />
</figure>

{/* ![frogrevolution](/static/images/devspaces/frog-revolution.webp) */}
Change is hard, change takes time, but ultimatly, once change happens and we look back at the old way of doing things, we always
smile and think "how did we do that in the past??"... How did we do music before audio streaming platforms?
Ah yes, we had those vinyl records, clunky cassette tapes, then later CDs to carry around with us,
life is so convenient these days with streaming platforms.
How did we do software before the likes of office 365, google doc etc...
Ah yes, we had to copy that floppy disk, burn that DVD, install that software, and upgrade regularly.
Life is so convenient these days, but only through adaptation and adoption.
Here adoption is the key, the solution is ready, it's time for you to make the shift to DevSpaces on OpenShift. Now.
